Info positions : [ 7  9 10 11 12 13 14 15]
Target Info positions : [ 7  9 10 11 12 13 14 15]
Frozen positions : [0 1 2 3 4 5 6 8]
Code : polar 
embed dim : 64 
Rate Profile : polar
Batch size : 8192
Validation SNR : 3.0
Number of heads : 1
Number of layers: 3
Positional encoding : static
Layers : compelete
Print frequency: 100
Num of steps: 10000
64
Training Model for 8,16 anew
Number of parameters : 150471
Did not find standard validation data
Need to save for: 1000
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[0/10000] At 3 dB, Loss: 1.6850737, Train BER (3 dB) : 0.4495392, Valid BER: 0.4982758, Tgt BER: 0.4982758, Noiseless BER 0.4912262, Valid BLER : 0.9655762
Time for one step is 0.0028 minutes
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[100/10000] At 3 dB, Loss: 0.6941945, Train BER (3 dB) : 0.2605133, Valid BER: 0.2600098, Tgt BER: 0.2600098, Noiseless BER 0.1726990, Valid BLER : 0.8896484
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[200/10000] At 3 dB, Loss: 0.6330436, Train BER (3 dB) : 0.2339783, Valid BER: 0.2183990, Tgt BER: 0.2183990, Noiseless BER 0.0870514, Valid BLER : 0.7551270
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[300/10000] At 3 dB, Loss: 0.5758700, Train BER (3 dB) : 0.2035828, Valid BER: 0.1840363, Tgt BER: 0.1840363, Noiseless BER 0.0285034, Valid BLER : 0.5814209
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[400/10000] At 3 dB, Loss: 0.5507249, Train BER (3 dB) : 0.1925507, Valid BER: 0.1758881, Tgt BER: 0.1758881, Noiseless BER 0.0034027, Valid BLER : 0.5041504
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[500/10000] At 3 dB, Loss: 0.5339726, Train BER (3 dB) : 0.1881561, Valid BER: 0.1700745, Tgt BER: 0.1700745, Noiseless BER 0.0007019, Valid BLER : 0.5131836
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[600/10000] At 3 dB, Loss: 0.5039084, Train BER (3 dB) : 0.1802216, Valid BER: 0.1655884, Tgt BER: 0.1655884, Noiseless BER 0.0000000, Valid BLER : 0.5129395
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[700/10000] At 3 dB, Loss: 0.4774321, Train BER (3 dB) : 0.1755371, Valid BER: 0.1589966, Tgt BER: 0.1589966, Noiseless BER 0.0000000, Valid BLER : 0.5312500
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[800/10000] At 3 dB, Loss: 0.4619287, Train BER (3 dB) : 0.1701660, Valid BER: 0.1623993, Tgt BER: 0.1623993, Noiseless BER 0.0000000, Valid BLER : 0.5379639
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[900/10000] At 3 dB, Loss: 0.4384194, Train BER (3 dB) : 0.1660614, Valid BER: 0.1593933, Tgt BER: 0.1593933, Noiseless BER 0.0000000, Valid BLER : 0.5512695
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[1000/10000] At 3 dB, Loss: 0.4287521, Train BER (3 dB) : 0.1659088, Valid BER: 0.1562805, Tgt BER: 0.1562805, Noiseless BER 0.0000000, Valid BLER : 0.5458984
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[1100/10000] At 3 dB, Loss: 0.4183256, Train BER (3 dB) : 0.1631012, Valid BER: 0.1620331, Tgt BER: 0.1620331, Noiseless BER 0.0000000, Valid BLER : 0.5628662
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[1200/10000] At 3 dB, Loss: 0.4041221, Train BER (3 dB) : 0.1579742, Valid BER: 0.1573944, Tgt BER: 0.1573944, Noiseless BER 0.0000000, Valid BLER : 0.5493164
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[1300/10000] At 3 dB, Loss: 0.4016026, Train BER (3 dB) : 0.1601105, Valid BER: 0.1536865, Tgt BER: 0.1536865, Noiseless BER 0.0000000, Valid BLER : 0.5368652
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[1400/10000] At 3 dB, Loss: 0.3820149, Train BER (3 dB) : 0.1559448, Valid BER: 0.1511841, Tgt BER: 0.1511841, Noiseless BER 0.0000000, Valid BLER : 0.5324707
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[1500/10000] At 3 dB, Loss: 0.3869562, Train BER (3 dB) : 0.1573029, Valid BER: 0.1514893, Tgt BER: 0.1514893, Noiseless BER 0.0000000, Valid BLER : 0.5325928
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[1600/10000] At 3 dB, Loss: 0.3699347, Train BER (3 dB) : 0.1526947, Valid BER: 0.1461029, Tgt BER: 0.1461029, Noiseless BER 0.0000000, Valid BLER : 0.5191650
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[1700/10000] At 3 dB, Loss: 0.3769999, Train BER (3 dB) : 0.1580811, Valid BER: 0.1510925, Tgt BER: 0.1510925, Noiseless BER 0.0000000, Valid BLER : 0.5296631
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[1800/10000] At 3 dB, Loss: 0.3660845, Train BER (3 dB) : 0.1522369, Valid BER: 0.1498566, Tgt BER: 0.1498566, Noiseless BER 0.0000000, Valid BLER : 0.5090332
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[1900/10000] At 3 dB, Loss: 0.3621008, Train BER (3 dB) : 0.1524200, Valid BER: 0.1491394, Tgt BER: 0.1491394, Noiseless BER 0.0000000, Valid BLER : 0.5174561
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[2000/10000] At 3 dB, Loss: 0.3558738, Train BER (3 dB) : 0.1519012, Valid BER: 0.1459198, Tgt BER: 0.1459198, Noiseless BER 0.0000000, Valid BLER : 0.5100098
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[2100/10000] At 3 dB, Loss: 0.3580259, Train BER (3 dB) : 0.1501007, Valid BER: 0.1456146, Tgt BER: 0.1456146, Noiseless BER 0.0000000, Valid BLER : 0.5018311
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[2200/10000] At 3 dB, Loss: 0.3655528, Train BER (3 dB) : 0.1528931, Valid BER: 0.1464844, Tgt BER: 0.1464844, Noiseless BER 0.0000000, Valid BLER : 0.4953613
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[2300/10000] At 3 dB, Loss: 0.3665484, Train BER (3 dB) : 0.1555786, Valid BER: 0.1429291, Tgt BER: 0.1429291, Noiseless BER 0.0000000, Valid BLER : 0.4981689
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[2400/10000] At 3 dB, Loss: 0.3581205, Train BER (3 dB) : 0.1510315, Valid BER: 0.1431580, Tgt BER: 0.1431580, Noiseless BER 0.0000000, Valid BLER : 0.4914551
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[2500/10000] At 3 dB, Loss: 0.3556546, Train BER (3 dB) : 0.1510162, Valid BER: 0.1450500, Tgt BER: 0.1450500, Noiseless BER 0.0000000, Valid BLER : 0.5029297
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[2600/10000] At 3 dB, Loss: 0.3519062, Train BER (3 dB) : 0.1472168, Valid BER: 0.1442566, Tgt BER: 0.1442566, Noiseless BER 0.0000000, Valid BLER : 0.5062256
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[2700/10000] At 3 dB, Loss: 0.3425354, Train BER (3 dB) : 0.1434631, Valid BER: 0.1438599, Tgt BER: 0.1438599, Noiseless BER 0.0000000, Valid BLER : 0.4984131
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[2800/10000] At 3 dB, Loss: 0.3519193, Train BER (3 dB) : 0.1490173, Valid BER: 0.1413879, Tgt BER: 0.1413879, Noiseless BER 0.0000000, Valid BLER : 0.4957275
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[2900/10000] At 3 dB, Loss: 0.3480442, Train BER (3 dB) : 0.1456451, Valid BER: 0.1437988, Tgt BER: 0.1437988, Noiseless BER 0.0000000, Valid BLER : 0.4957275
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[3000/10000] At 3 dB, Loss: 0.3536385, Train BER (3 dB) : 0.1487579, Valid BER: 0.1409454, Tgt BER: 0.1409454, Noiseless BER 0.0000000, Valid BLER : 0.4947510
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[3100/10000] At 3 dB, Loss: 0.3468842, Train BER (3 dB) : 0.1465149, Valid BER: 0.1408234, Tgt BER: 0.1408234, Noiseless BER 0.0000000, Valid BLER : 0.4893799
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[3200/10000] At 3 dB, Loss: 0.3533786, Train BER (3 dB) : 0.1477356, Valid BER: 0.1432190, Tgt BER: 0.1432190, Noiseless BER 0.0000000, Valid BLER : 0.4970703
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[3300/10000] At 3 dB, Loss: 0.3539501, Train BER (3 dB) : 0.1473694, Valid BER: 0.1373138, Tgt BER: 0.1373138, Noiseless BER 0.0000000, Valid BLER : 0.4897461
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[3400/10000] At 3 dB, Loss: 0.3475590, Train BER (3 dB) : 0.1440125, Valid BER: 0.1375580, Tgt BER: 0.1375580, Noiseless BER 0.0000000, Valid BLER : 0.4841309
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[3500/10000] At 3 dB, Loss: 0.3432553, Train BER (3 dB) : 0.1438751, Valid BER: 0.1341705, Tgt BER: 0.1341705, Noiseless BER 0.0000000, Valid BLER : 0.4758301
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[3600/10000] At 3 dB, Loss: 0.3429412, Train BER (3 dB) : 0.1430359, Valid BER: 0.1331177, Tgt BER: 0.1331177, Noiseless BER 0.0000000, Valid BLER : 0.4703369
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[3700/10000] At 3 dB, Loss: 0.3418095, Train BER (3 dB) : 0.1407471, Valid BER: 0.1265259, Tgt BER: 0.1265259, Noiseless BER 0.0000000, Valid BLER : 0.4549561
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[3800/10000] At 3 dB, Loss: 0.3382058, Train BER (3 dB) : 0.1359100, Valid BER: 0.1203766, Tgt BER: 0.1203766, Noiseless BER 0.0000000, Valid BLER : 0.4309082
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[3900/10000] At 3 dB, Loss: 0.3270795, Train BER (3 dB) : 0.1286316, Valid BER: 0.1173706, Tgt BER: 0.1173706, Noiseless BER 0.0000000, Valid BLER : 0.4254150
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[4000/10000] At 3 dB, Loss: 0.3246320, Train BER (3 dB) : 0.1250610, Valid BER: 0.1063080, Tgt BER: 0.1063080, Noiseless BER 0.0000000, Valid BLER : 0.3891602
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[4100/10000] At 3 dB, Loss: 0.3102490, Train BER (3 dB) : 0.1177521, Valid BER: 0.0986786, Tgt BER: 0.0986786, Noiseless BER 0.0000000, Valid BLER : 0.3565674
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[4200/10000] At 3 dB, Loss: 0.3048280, Train BER (3 dB) : 0.1131592, Valid BER: 0.0936127, Tgt BER: 0.0936127, Noiseless BER 0.0000000, Valid BLER : 0.3435059
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[4300/10000] At 3 dB, Loss: 0.3076669, Train BER (3 dB) : 0.1144104, Valid BER: 0.0942993, Tgt BER: 0.0942993, Noiseless BER 0.0000000, Valid BLER : 0.3364258
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[4400/10000] At 3 dB, Loss: 0.2889626, Train BER (3 dB) : 0.1067505, Valid BER: 0.0913849, Tgt BER: 0.0913849, Noiseless BER 0.0000000, Valid BLER : 0.3253174
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[4500/10000] At 3 dB, Loss: 0.2830994, Train BER (3 dB) : 0.1041565, Valid BER: 0.0898743, Tgt BER: 0.0898743, Noiseless BER 0.0000000, Valid BLER : 0.3153076
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[4600/10000] At 3 dB, Loss: 0.2848342, Train BER (3 dB) : 0.1038361, Valid BER: 0.0897980, Tgt BER: 0.0897980, Noiseless BER 0.0000000, Valid BLER : 0.3125000
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[4700/10000] At 3 dB, Loss: 0.2823235, Train BER (3 dB) : 0.1049805, Valid BER: 0.0874481, Tgt BER: 0.0874481, Noiseless BER 0.0000000, Valid BLER : 0.3050537
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[4800/10000] At 3 dB, Loss: 0.2797594, Train BER (3 dB) : 0.1034851, Valid BER: 0.0871735, Tgt BER: 0.0871735, Noiseless BER 0.0000000, Valid BLER : 0.3062744
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[4900/10000] At 3 dB, Loss: 0.2769909, Train BER (3 dB) : 0.1019592, Valid BER: 0.0866241, Tgt BER: 0.0866241, Noiseless BER 0.0000000, Valid BLER : 0.3017578
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[5000/10000] At 3 dB, Loss: 0.2754576, Train BER (3 dB) : 0.1028900, Valid BER: 0.0871124, Tgt BER: 0.0871124, Noiseless BER 0.0000000, Valid BLER : 0.2989502
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[5100/10000] At 3 dB, Loss: 0.2705113, Train BER (3 dB) : 0.1000977, Valid BER: 0.0866852, Tgt BER: 0.0866852, Noiseless BER 0.0000000, Valid BLER : 0.2979736
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[5200/10000] At 3 dB, Loss: 0.2696306, Train BER (3 dB) : 0.0989838, Valid BER: 0.0854187, Tgt BER: 0.0854187, Noiseless BER 0.0000000, Valid BLER : 0.2879639
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[5300/10000] At 3 dB, Loss: 0.2637786, Train BER (3 dB) : 0.0986176, Valid BER: 0.0838776, Tgt BER: 0.0838776, Noiseless BER 0.0000000, Valid BLER : 0.2893066
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[5400/10000] At 3 dB, Loss: 0.2565852, Train BER (3 dB) : 0.0951843, Valid BER: 0.0858002, Tgt BER: 0.0858002, Noiseless BER 0.0000000, Valid BLER : 0.2860107
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[5500/10000] At 3 dB, Loss: 0.2611482, Train BER (3 dB) : 0.0963287, Valid BER: 0.0849304, Tgt BER: 0.0849304, Noiseless BER 0.0000000, Valid BLER : 0.2847900
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[5600/10000] At 3 dB, Loss: 0.2606956, Train BER (3 dB) : 0.0971375, Valid BER: 0.0836334, Tgt BER: 0.0836334, Noiseless BER 0.0000000, Valid BLER : 0.2796631
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[5700/10000] At 3 dB, Loss: 0.2589633, Train BER (3 dB) : 0.0963898, Valid BER: 0.0866241, Tgt BER: 0.0866241, Noiseless BER 0.0000000, Valid BLER : 0.2888184
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[5800/10000] At 3 dB, Loss: 0.2524596, Train BER (3 dB) : 0.0936737, Valid BER: 0.0843048, Tgt BER: 0.0843048, Noiseless BER 0.0000000, Valid BLER : 0.2827148
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[5900/10000] At 3 dB, Loss: 0.2633479, Train BER (3 dB) : 0.0991669, Valid BER: 0.0879517, Tgt BER: 0.0879517, Noiseless BER 0.0000000, Valid BLER : 0.2819824
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[6000/10000] At 3 dB, Loss: 0.2485798, Train BER (3 dB) : 0.0937347, Valid BER: 0.0852203, Tgt BER: 0.0852203, Noiseless BER 0.0000000, Valid BLER : 0.2850342
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[6100/10000] At 3 dB, Loss: 0.2505713, Train BER (3 dB) : 0.0939331, Valid BER: 0.0865021, Tgt BER: 0.0865021, Noiseless BER 0.0000000, Valid BLER : 0.2813721
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[6200/10000] At 3 dB, Loss: 0.2509066, Train BER (3 dB) : 0.0938416, Valid BER: 0.0863495, Tgt BER: 0.0863495, Noiseless BER 0.0000000, Valid BLER : 0.2822266
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[6300/10000] At 3 dB, Loss: 0.2539105, Train BER (3 dB) : 0.0944214, Valid BER: 0.0817261, Tgt BER: 0.0817261, Noiseless BER 0.0000000, Valid BLER : 0.2756348
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[6400/10000] At 3 dB, Loss: 0.2552179, Train BER (3 dB) : 0.0955963, Valid BER: 0.0857391, Tgt BER: 0.0857391, Noiseless BER 0.0000000, Valid BLER : 0.2890625
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[6500/10000] At 3 dB, Loss: 0.2425003, Train BER (3 dB) : 0.0908966, Valid BER: 0.0849457, Tgt BER: 0.0849457, Noiseless BER 0.0000000, Valid BLER : 0.2773438
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[6600/10000] At 3 dB, Loss: 0.2422189, Train BER (3 dB) : 0.0910950, Valid BER: 0.0879059, Tgt BER: 0.0879059, Noiseless BER 0.0000000, Valid BLER : 0.2857666
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[6700/10000] At 3 dB, Loss: 0.2455593, Train BER (3 dB) : 0.0923615, Valid BER: 0.0844421, Tgt BER: 0.0844421, Noiseless BER 0.0000000, Valid BLER : 0.2766113
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[6800/10000] At 3 dB, Loss: 0.2462813, Train BER (3 dB) : 0.0940094, Valid BER: 0.0849762, Tgt BER: 0.0849762, Noiseless BER 0.0000000, Valid BLER : 0.2836914
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[6900/10000] At 3 dB, Loss: 0.2418945, Train BER (3 dB) : 0.0900269, Valid BER: 0.0869293, Tgt BER: 0.0869293, Noiseless BER 0.0000000, Valid BLER : 0.2797852
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[7000/10000] At 3 dB, Loss: 0.2397572, Train BER (3 dB) : 0.0906372, Valid BER: 0.0861969, Tgt BER: 0.0861969, Noiseless BER 0.0000000, Valid BLER : 0.2849121
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[7100/10000] At 3 dB, Loss: 0.2406959, Train BER (3 dB) : 0.0906219, Valid BER: 0.0838470, Tgt BER: 0.0838470, Noiseless BER 0.0000000, Valid BLER : 0.2772217
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[7200/10000] At 3 dB, Loss: 0.2484380, Train BER (3 dB) : 0.0941010, Valid BER: 0.0839386, Tgt BER: 0.0839386, Noiseless BER 0.0000000, Valid BLER : 0.2794189
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[7300/10000] At 3 dB, Loss: 0.2388632, Train BER (3 dB) : 0.0920258, Valid BER: 0.0838928, Tgt BER: 0.0838928, Noiseless BER 0.0000000, Valid BLER : 0.2736816
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[7400/10000] At 3 dB, Loss: 0.2426843, Train BER (3 dB) : 0.0918732, Valid BER: 0.0863190, Tgt BER: 0.0863190, Noiseless BER 0.0000000, Valid BLER : 0.2854004
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[7500/10000] At 3 dB, Loss: 0.2452217, Train BER (3 dB) : 0.0929871, Valid BER: 0.0834045, Tgt BER: 0.0834045, Noiseless BER 0.0000000, Valid BLER : 0.2788086
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[7600/10000] At 3 dB, Loss: 0.2363356, Train BER (3 dB) : 0.0900116, Valid BER: 0.0848083, Tgt BER: 0.0848083, Noiseless BER 0.0000000, Valid BLER : 0.2784424
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[7700/10000] At 3 dB, Loss: 0.2360597, Train BER (3 dB) : 0.0888824, Valid BER: 0.0859833, Tgt BER: 0.0859833, Noiseless BER 0.0000000, Valid BLER : 0.2863770
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[7800/10000] At 3 dB, Loss: 0.2337994, Train BER (3 dB) : 0.0895538, Valid BER: 0.0872955, Tgt BER: 0.0872955, Noiseless BER 0.0000000, Valid BLER : 0.2875977
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[7900/10000] At 3 dB, Loss: 0.2397346, Train BER (3 dB) : 0.0923615, Valid BER: 0.0824127, Tgt BER: 0.0824127, Noiseless BER 0.0000000, Valid BLER : 0.2742920
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[8000/10000] At 3 dB, Loss: 0.2437023, Train BER (3 dB) : 0.0926971, Valid BER: 0.0834503, Tgt BER: 0.0834503, Noiseless BER 0.0000000, Valid BLER : 0.2775879
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[8100/10000] At 3 dB, Loss: 0.2334535, Train BER (3 dB) : 0.0893555, Valid BER: 0.0844421, Tgt BER: 0.0844421, Noiseless BER 0.0000000, Valid BLER : 0.2794189
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[8200/10000] At 3 dB, Loss: 0.2298633, Train BER (3 dB) : 0.0869904, Valid BER: 0.0831757, Tgt BER: 0.0831757, Noiseless BER 0.0000000, Valid BLER : 0.2823486
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[8300/10000] At 3 dB, Loss: 0.2343160, Train BER (3 dB) : 0.0887604, Valid BER: 0.0848083, Tgt BER: 0.0848083, Noiseless BER 0.0000000, Valid BLER : 0.2838135
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[8400/10000] At 3 dB, Loss: 0.2332505, Train BER (3 dB) : 0.0896912, Valid BER: 0.0837708, Tgt BER: 0.0837708, Noiseless BER 0.0000000, Valid BLER : 0.2792969
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[8500/10000] At 3 dB, Loss: 0.2322255, Train BER (3 dB) : 0.0893707, Valid BER: 0.0879822, Tgt BER: 0.0879822, Noiseless BER 0.0000000, Valid BLER : 0.2910156
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[8600/10000] At 3 dB, Loss: 0.2337284, Train BER (3 dB) : 0.0882874, Valid BER: 0.0818481, Tgt BER: 0.0818481, Noiseless BER 0.0000000, Valid BLER : 0.2711182
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[8700/10000] At 3 dB, Loss: 0.2364854, Train BER (3 dB) : 0.0910950, Valid BER: 0.0855103, Tgt BER: 0.0855103, Noiseless BER 0.0000000, Valid BLER : 0.2811279
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[8800/10000] At 3 dB, Loss: 0.2327348, Train BER (3 dB) : 0.0899811, Valid BER: 0.0859528, Tgt BER: 0.0859528, Noiseless BER 0.0000000, Valid BLER : 0.2803955
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[8900/10000] At 3 dB, Loss: 0.2425842, Train BER (3 dB) : 0.0923462, Valid BER: 0.0829315, Tgt BER: 0.0829315, Noiseless BER 0.0000000, Valid BLER : 0.2779541
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[9000/10000] At 3 dB, Loss: 0.2288693, Train BER (3 dB) : 0.0874939, Valid BER: 0.0836945, Tgt BER: 0.0836945, Noiseless BER 0.0000000, Valid BLER : 0.2761230
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[9100/10000] At 3 dB, Loss: 0.2308373, Train BER (3 dB) : 0.0900116, Valid BER: 0.0887604, Tgt BER: 0.0887604, Noiseless BER 0.0000000, Valid BLER : 0.2890625
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[9200/10000] At 3 dB, Loss: 0.2273402, Train BER (3 dB) : 0.0882568, Valid BER: 0.0843964, Tgt BER: 0.0843964, Noiseless BER 0.0000000, Valid BLER : 0.2750244
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[9300/10000] At 3 dB, Loss: 0.2416277, Train BER (3 dB) : 0.0942230, Valid BER: 0.0846710, Tgt BER: 0.0846710, Noiseless BER 0.0000000, Valid BLER : 0.2832031
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[9400/10000] At 3 dB, Loss: 0.2229514, Train BER (3 dB) : 0.0869293, Valid BER: 0.0827637, Tgt BER: 0.0827637, Noiseless BER 0.0000000, Valid BLER : 0.2745361
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[9500/10000] At 3 dB, Loss: 0.2339633, Train BER (3 dB) : 0.0904388, Valid BER: 0.0839844, Tgt BER: 0.0839844, Noiseless BER 0.0000000, Valid BLER : 0.2797852
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[9600/10000] At 3 dB, Loss: 0.2333185, Train BER (3 dB) : 0.0902405, Valid BER: 0.0810089, Tgt BER: 0.0810089, Noiseless BER 0.0000000, Valid BLER : 0.2745361
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[9700/10000] At 3 dB, Loss: 0.2251963, Train BER (3 dB) : 0.0863800, Valid BER: 0.0861969, Tgt BER: 0.0861969, Noiseless BER 0.0000000, Valid BLER : 0.2784424
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[9800/10000] At 3 dB, Loss: 0.2377731, Train BER (3 dB) : 0.0913544, Valid BER: 0.0850677, Tgt BER: 0.0850677, Noiseless BER 0.0000000, Valid BLER : 0.2768555
Shape of attn for special data: torch.Size([1, 1, 16, 16])
[9900/10000] At 3 dB, Loss: 0.2356295, Train BER (3 dB) : 0.0906525, Valid BER: 0.0830841, Tgt BER: 0.0830841, Noiseless BER 0.0000000, Valid BLER : 0.2731934
attn list dim 0 100
attn list dim 1 ,  3
attn list dim 2 ,  1
attn list dim 3 ,  16
attn list dim 4 ,  16
Complete
Info positions : [ 7  9 10 11 12 13 14 15]
Target Info positions : [ 7  9 10 11 12 13 14 15]
Frozen positions : [0 1 2 3 4 5 6 8]
Code : polar 
embed dim : 64 
Rate Profile : polar
Batch size : 128
Validation SNR : None
Number of heads : 1
Number of layers: 3
Positional encoding : static
Layers : compelete
Print frequency: 100
Num of steps: 400000
64
TESTING :
Model loaded at step 1000
tensor([[0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')
Test SNRs :  [-10.0, -8.421052631578947, -6.842105263157895, -5.2631578947368425, -3.6842105263157894, -2.1052631578947363, -0.526315789473685, 1.0526315789473681, 2.6315789473684212, 4.210526315789474, 5.789473684210527, 7.368421052631579, 8.94736842105263, 10.526315789473685, 12.105263157894736, 13.684210526315791, 15.263157894736842, 16.842105263157894, 18.42105263157895, 20.0]
BERs of Xformer: [0.480375000834465, 0.46447499990463254, 0.456887498497963, 0.4392000019550323, 0.4171625018119812, 0.3810374975204468, 0.3331624984741211, 0.2731374979019165, 0.20527500212192532, 0.13378750011324883, 0.06875000074505806, 0.03176249992102385, 0.01183749996125698, 0.005775000061839819, 0.004737500101327896, 0.004675000067800283, 0.004675000067800283, 0.004675000067800283, 0.004675000067800283, 0.004675000067800283]
BERs of SC decoding: [0.45902499854564666, 0.43518750071525575, 0.4060999989509583, 0.3721874952316284, 0.3147375077009201, 0.23892499804496764, 0.1523499995470047, 0.0751749999821186, 0.02658749986439943, 0.005862499913200736, 0.0004375000105937943, 0.00010000000329455361, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of SCL decoding: [0.4578250050544739, 0.43532499969005584, 0.40581249892711635, 0.37163749933242796, 0.31587499678134917, 0.2383875012397766, 0.1521750003099442, 0.07487500011920929, 0.026574999839067456, 0.005862499913200736, 0.0004375000105937943, 0.00010000000329455361, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of ML: [0.4578250050544739, 0.43532499969005584, 0.40581249892711635, 0.37163749933242796, 0.31587499678134917, 0.2383875012397766, 0.1521750003099442, 0.07487500011920929, 0.026574999839067456, 0.005862499913200736, 0.0004375000105937943, 0.00010000000329455361, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of ML: [0.9490999999999999, 0.9177000000000001, 0.8700000000000001, 0.8041, 0.6955999999999998, 0.5428000000000001, 0.35950000000000004, 0.179, 0.0641, 0.015, 0.0012000000000000001, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of bitML: [0.4530500054359436, 0.42973749637603764, 0.4023124992847443, 0.3666499972343445, 0.31201249957084654, 0.23526249974966046, 0.1506999999284744, 0.07486249953508377, 0.026200000010430807, 0.005749999941326678, 0.0004375000105937943, 0.00010000000329455361, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of bitML: [0.9632, 0.9349000000000001, 0.8904, 0.8264999999999999, 0.7177000000000001, 0.5589, 0.3709, 0.18330000000000002, 0.06470000000000001, 0.0151, 0.0012000000000000001, 0.0002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of Xformer: [0.9892999999999998, 0.9834, 0.9816999999999999, 0.9689, 0.9537, 0.9195, 0.8627999999999999, 0.7689, 0.6313000000000001, 0.4554, 0.26430000000000003, 0.1382, 0.0632, 0.041499999999999995, 0.037599999999999995, 0.037399999999999996, 0.037399999999999996, 0.037399999999999996, 0.037399999999999996, 0.037399999999999996]
Time taken = 24.96058416366577 seconds
tensor([[0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')
Info positions : [ 7  9 10 11 12 13 14 15]
Target Info positions : [ 7  9 10 11 12 13 14 15]
Frozen positions : [0 1 2 3 4 5 6 8]
Code : polar 
embed dim : 64 
Rate Profile : polar
Batch size : 128
Validation SNR : None
Number of heads : 1
Number of layers: 3
Positional encoding : static
Layers : compelete
Print frequency: 100
Num of steps: 400000
64
TESTING :
Model loaded at step 2000
tensor([[0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')
Test SNRs :  [-10.0, -8.421052631578947, -6.842105263157895, -5.2631578947368425, -3.6842105263157894, -2.1052631578947363, -0.526315789473685, 1.0526315789473681, 2.6315789473684212, 4.210526315789474, 5.789473684210527, 7.368421052631579, 8.94736842105263, 10.526315789473685, 12.105263157894736, 13.684210526315791, 15.263157894736842, 16.842105263157894, 18.42105263157895, 20.0]
BERs of Xformer: [0.48406249880790714, 0.47752499878406524, 0.46097500026226046, 0.44983749687671665, 0.4260500013828277, 0.3952375024557114, 0.35148749947547914, 0.2917499989271164, 0.2226999998092651, 0.14881249815225603, 0.07858750075101853, 0.030475000105798244, 0.008850000007078052, 0.0011500000080559402, 7.500000356230885e-05, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of SC decoding: [0.4567999988794327, 0.43536249697208407, 0.40753750205039985, 0.3686624974012376, 0.31343750059604647, 0.2343500018119812, 0.15419999957084654, 0.07896250039339064, 0.02554999999701977, 0.005224999971687794, 0.00038750000821892173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of SCL decoding: [0.45707500576972965, 0.4360499978065491, 0.4075874984264374, 0.3678624987602234, 0.31365000307559965, 0.23354999870061874, 0.15384999960660936, 0.07848749980330468, 0.02546250019222498, 0.005224999971687794, 0.00038750000821892173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of ML: [0.45707500576972965, 0.4360499978065491, 0.4075874984264374, 0.3678624987602234, 0.31365000307559965, 0.23354999870061874, 0.15384999960660936, 0.07848749980330468, 0.02546250019222498, 0.005224999971687794, 0.00038750000821892173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of ML: [0.9438999999999999, 0.9146000000000001, 0.8744999999999999, 0.8024, 0.6956, 0.5386000000000001, 0.3581, 0.1887, 0.063, 0.012499999999999999, 0.0009000000000000001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of bitML: [0.45107499957084657, 0.4289624989032745, 0.40217500030994413, 0.3632500022649765, 0.30846249759197236, 0.2313375025987625, 0.15213749855756759, 0.07775000110268593, 0.025712500326335427, 0.005162499984726309, 0.00038750000821892173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of bitML: [0.9590000000000001, 0.9339999999999999, 0.8943, 0.8262999999999999, 0.7153, 0.5575, 0.3679, 0.1921, 0.064, 0.012399999999999998, 0.0009000000000000001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of Xformer: [0.9924, 0.988, 0.9829999999999998, 0.9788, 0.9612999999999998, 0.935, 0.8851, 0.7913999999999999, 0.655, 0.4623, 0.26339999999999997, 0.1093, 0.0302, 0.0041, 0.0004, 0.0, 0.0, 0.0, 0.0, 0.0]
Time taken = 24.57031559944153 seconds
tensor([[0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')
Info positions : [ 7  9 10 11 12 13 14 15]
Target Info positions : [ 7  9 10 11 12 13 14 15]
Frozen positions : [0 1 2 3 4 5 6 8]
Code : polar 
embed dim : 64 
Rate Profile : polar
Batch size : 128
Validation SNR : None
Number of heads : 1
Number of layers: 3
Positional encoding : static
Layers : compelete
Print frequency: 100
Num of steps: 400000
64
TESTING :
Model loaded at step 3000
tensor([[0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')
Test SNRs :  [-10.0, -8.421052631578947, -6.842105263157895, -5.2631578947368425, -3.6842105263157894, -2.1052631578947363, -0.526315789473685, 1.0526315789473681, 2.6315789473684212, 4.210526315789474, 5.789473684210527, 7.368421052631579, 8.94736842105263, 10.526315789473685, 12.105263157894736, 13.684210526315791, 15.263157894736842, 16.842105263157894, 18.42105263157895, 20.0]
BERs of Xformer: [0.4878250002861023, 0.47922499775886535, 0.46923750042915346, 0.4531999975442887, 0.4359875023365021, 0.40787499547004696, 0.3690749973058701, 0.3122500002384186, 0.24041249901056294, 0.16257500052452087, 0.09137500002980231, 0.04182500019669533, 0.016187500022351742, 0.008050000015646219, 0.006812499882653355, 0.006762499921023846, 0.006762499921023846, 0.006762499921023846, 0.006762499921023846, 0.006762499921023846]
BERs of SC decoding: [0.45344999730587, 0.4379999995231629, 0.4088625013828278, 0.3700375020503998, 0.31481249630451197, 0.23929999768733978, 0.15268750190734864, 0.08138749971985818, 0.025862500071525574, 0.004674999974668026, 0.00033750000293366613, 2.5000001187436283e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of SCL decoding: [0.45329999923706055, 0.4388874977827072, 0.40923750102519985, 0.37020000219345095, 0.31427499651908875, 0.23946250081062315, 0.1527999997138977, 0.0812375009059906, 0.025599999912083147, 0.004674999974668026, 0.00033750000293366613, 2.5000001187436283e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of ML: [0.45329999923706055, 0.4388874977827072, 0.40923750102519985, 0.37020000219345095, 0.31427499651908875, 0.23946250081062315, 0.1527999997138977, 0.0812375009059906, 0.025599999912083147, 0.004674999974668026, 0.00033750000293366613, 2.5000001187436283e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of ML: [0.9436, 0.9173, 0.8786, 0.8086000000000001, 0.7003999999999999, 0.5431, 0.355, 0.19099999999999998, 0.0623, 0.011099999999999999, 0.001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of bitML: [0.44766249954700477, 0.43281250000000004, 0.40388750433921816, 0.36522499620914467, 0.30977500081062326, 0.2341999977827072, 0.15101249814033507, 0.08054999858140946, 0.025537499971687794, 0.004650000017136335, 0.00033750000293366613, 2.5000001187436283e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of bitML: [0.9585, 0.9360999999999999, 0.8968999999999999, 0.8289, 0.7192, 0.5566, 0.3661000000000001, 0.195, 0.0638, 0.011099999999999999, 0.001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of Xformer: [0.993, 0.9903, 0.9860999999999998, 0.9786, 0.9665, 0.9415999999999998, 0.8989, 0.8128, 0.6815, 0.4965, 0.2942, 0.1496, 0.06559999999999999, 0.0408, 0.037200000000000004, 0.037, 0.037, 0.037, 0.037, 0.037]
Time taken = 24.841514348983765 seconds
tensor([[0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')
Info positions : [ 7  9 10 11 12 13 14 15]
Target Info positions : [ 7  9 10 11 12 13 14 15]
Frozen positions : [0 1 2 3 4 5 6 8]
Code : polar 
embed dim : 64 
Rate Profile : polar
Batch size : 128
Validation SNR : None
Number of heads : 1
Number of layers: 3
Positional encoding : static
Layers : compelete
Print frequency: 100
Num of steps: 400000
64
TESTING :
Model loaded at step 4000
tensor([[0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')
Test SNRs :  [-10.0, -8.421052631578947, -6.842105263157895, -5.2631578947368425, -3.6842105263157894, -2.1052631578947363, -0.526315789473685, 1.0526315789473681, 2.6315789473684212, 4.210526315789474, 5.789473684210527, 7.368421052631579, 8.94736842105263, 10.526315789473685, 12.105263157894736, 13.684210526315791, 15.263157894736842, 16.842105263157894, 18.42105263157895, 20.0]
BERs of Xformer: [0.4807500004768372, 0.47620000243186955, 0.46406249701976776, 0.4451625019311905, 0.4285499960184098, 0.3973875015974045, 0.3524999976158142, 0.2947999984025955, 0.22619999945163727, 0.15567499995231626, 0.0962249994277954, 0.05601250007748604, 0.03852499984204769, 0.032949999906122684, 0.03172500003129244, 0.031712500005960466, 0.031712500005960466, 0.031712500005960466, 0.031712500005960466, 0.031712500005960466]
BERs of SC decoding: [0.452287495136261, 0.43861250281333924, 0.4085374981164932, 0.3652750045061112, 0.31212500035762786, 0.23898750394582752, 0.15620000064373016, 0.07457500100135803, 0.026637500524520873, 0.005374999972991645, 0.00036250000703148545, 5.0000002374872565e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of SCL decoding: [0.4524125039577484, 0.43869999945163723, 0.40852500498294825, 0.36503749787807466, 0.31128749847412107, 0.23758749961853026, 0.15567499846220018, 0.0744375005364418, 0.026487500593066215, 0.005374999972991645, 0.00036250000703148545, 5.0000002374872565e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of ML: [0.4524125039577484, 0.43869999945163723, 0.40852500498294825, 0.36503749787807466, 0.31128749847412107, 0.23758749961853026, 0.15567499846220018, 0.0744375005364418, 0.026487500593066215, 0.005374999972991645, 0.00036250000703148545, 5.0000002374872565e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of ML: [0.9445, 0.918, 0.8707, 0.7993000000000001, 0.6937999999999999, 0.5448000000000001, 0.3664, 0.18199999999999997, 0.0646, 0.0136, 0.001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of bitML: [0.44825000166893003, 0.43452499806880945, 0.40416250228881834, 0.3608125001192093, 0.30688750445842744, 0.23514999896287916, 0.15405000001192093, 0.07346250042319298, 0.02658750005066395, 0.0053749999031424515, 0.00036250000703148545, 5.0000002374872565e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of bitML: [0.9594999999999999, 0.9353999999999999, 0.8917999999999999, 0.8221, 0.7139999999999999, 0.5617000000000001, 0.3764, 0.18400000000000002, 0.06580000000000001, 0.0136, 0.001, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of Xformer: [0.9898, 0.9887, 0.9828, 0.9719, 0.9591999999999999, 0.9338000000000001, 0.8810000000000001, 0.7867999999999999, 0.6519, 0.47330000000000005, 0.305, 0.1805, 0.1186, 0.1006, 0.09720000000000001, 0.09720000000000001, 0.09720000000000001, 0.09720000000000001, 0.09720000000000001, 0.09720000000000001]
Time taken = 24.594390630722046 seconds
tensor([[0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')
Info positions : [ 7  9 10 11 12 13 14 15]
Target Info positions : [ 7  9 10 11 12 13 14 15]
Frozen positions : [0 1 2 3 4 5 6 8]
Code : polar 
embed dim : 64 
Rate Profile : polar
Batch size : 128
Validation SNR : None
Number of heads : 1
Number of layers: 3
Positional encoding : static
Layers : compelete
Print frequency: 100
Num of steps: 400000
64
TESTING :
Model loaded at step 5000
tensor([[0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')
Test SNRs :  [-10.0, -8.421052631578947, -6.842105263157895, -5.2631578947368425, -3.6842105263157894, -2.1052631578947363, -0.526315789473685, 1.0526315789473681, 2.6315789473684212, 4.210526315789474, 5.789473684210527, 7.368421052631579, 8.94736842105263, 10.526315789473685, 12.105263157894736, 13.684210526315791, 15.263157894736842, 16.842105263157894, 18.42105263157895, 20.0]
BERs of Xformer: [0.4789750039577484, 0.46594999730587, 0.4571875005960464, 0.44383750259876253, 0.4148874968290329, 0.3814249992370606, 0.3193374991416931, 0.2529499992728233, 0.16956249773502352, 0.09847500026226044, 0.05147499963641167, 0.030337500013411046, 0.024037500284612177, 0.022312499955296515, 0.022074999846518034, 0.022074999846518034, 0.022074999846518034, 0.022074999846518034, 0.022074999846518034, 0.022074999846518034]
BERs of SC decoding: [0.45417500138282774, 0.4344250023365021, 0.4101249992847442, 0.3706000030040741, 0.3084999978542328, 0.24145000278949735, 0.15219999998807907, 0.07858750075101852, 0.028375000320374964, 0.005862499983049929, 0.0006500000017695129, 1.2500000593718141e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of SCL decoding: [0.45356249809265137, 0.4340375036001205, 0.41007499396800995, 0.37043750286102295, 0.3075499951839447, 0.2414249986410141, 0.15160000026226042, 0.07849999964237213, 0.02834999989718199, 0.005899999965913593, 0.0006500000017695129, 1.2500000593718141e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of ML: [0.45356249809265137, 0.4340375036001205, 0.41007499396800995, 0.37043750286102295, 0.3075499951839447, 0.2414249986410141, 0.15160000026226042, 0.07849999964237213, 0.02834999989718199, 0.005899999965913593, 0.0006500000017695129, 1.2500000593718141e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of ML: [0.9415, 0.9147, 0.8774000000000001, 0.7974, 0.6924, 0.5496, 0.3525999999999999, 0.185, 0.0687, 0.0137, 0.0016, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of bitML: [0.45005000829696645, 0.4277999997138977, 0.4055249989032745, 0.36551249921321866, 0.30386250019073485, 0.23827500194311138, 0.14942499846220014, 0.07779999896883964, 0.02817499991506338, 0.005850000004284084, 0.0006374999997206033, 1.2500000593718141e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of bitML: [0.9566, 0.9323999999999999, 0.8972, 0.8188999999999999, 0.7127, 0.5658, 0.36, 0.18950000000000003, 0.06970000000000001, 0.013600000000000001, 0.0016, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of Xformer: [0.9873999999999999, 0.9825999999999999, 0.9769999999999999, 0.9621, 0.9398, 0.8965000000000001, 0.8083999999999999, 0.6794, 0.4924, 0.3101, 0.17830000000000001, 0.10969999999999999, 0.0854, 0.079, 0.07839999999999998, 0.07829999999999998, 0.07829999999999998, 0.07829999999999998, 0.07829999999999998, 0.07829999999999998]
Time taken = 25.09921407699585 seconds
tensor([[0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')
Info positions : [ 7  9 10 11 12 13 14 15]
Target Info positions : [ 7  9 10 11 12 13 14 15]
Frozen positions : [0 1 2 3 4 5 6 8]
Code : polar 
embed dim : 64 
Rate Profile : polar
Batch size : 128
Validation SNR : None
Number of heads : 1
Number of layers: 3
Positional encoding : static
Layers : compelete
Print frequency: 100
Num of steps: 400000
64
TESTING :
Model loaded at step 6000
tensor([[0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')
Test SNRs :  [-10.0, -8.421052631578947, -6.842105263157895, -5.2631578947368425, -3.6842105263157894, -2.1052631578947363, -0.526315789473685, 1.0526315789473681, 2.6315789473684212, 4.210526315789474, 5.789473684210527, 7.368421052631579, 8.94736842105263, 10.526315789473685, 12.105263157894736, 13.684210526315791, 15.263157894736842, 16.842105263157894, 18.42105263157895, 20.0]
BERs of Xformer: [0.48245000243186953, 0.4707874983549118, 0.45852499902248384, 0.44138749837875363, 0.41319999992847445, 0.3769625008106232, 0.32493750154972073, 0.2453125, 0.1609500005841255, 0.09007499963045122, 0.0458125002682209, 0.02826249971985817, 0.024624999985098837, 0.024137499928474426, 0.024125000275671483, 0.024125000275671483, 0.024125000275671483, 0.024125000275671483, 0.024125000275671483, 0.024125000275671483]
BERs of SC decoding: [0.4556874960660934, 0.43871250152587893, 0.4098499983549118, 0.3695124983787537, 0.3061624974012375, 0.23599999994039533, 0.1517750009894371, 0.07446250021457672, 0.024699999764561654, 0.0047874999931082135, 0.0005250000147498212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of SCL decoding: [0.4564875036478042, 0.4384375005960464, 0.409649994969368, 0.3696374982595444, 0.3053999990224838, 0.23587499707937237, 0.15174999982118606, 0.07387500032782555, 0.024687499925494193, 0.0047874999931082135, 0.0005250000147498212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of ML: [0.4564875036478042, 0.4384375005960464, 0.409649994969368, 0.3696374982595444, 0.3053999990224838, 0.23587499707937237, 0.15174999982118606, 0.07387500032782555, 0.024687499925494193, 0.0047874999931082135, 0.0005250000147498212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of ML: [0.9439, 0.9201999999999999, 0.8770000000000001, 0.8068, 0.688, 0.5357, 0.35139999999999993, 0.17609999999999998, 0.0602, 0.011300000000000001, 0.0012000000000000001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of bitML: [0.45082499980926516, 0.4353750020265579, 0.4037124991416931, 0.36386250257492064, 0.30148749947547915, 0.23250000178813932, 0.14980000108480454, 0.072562500461936, 0.024112499877810483, 0.004812500043772161, 0.000500000016472768, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of bitML: [0.9572999999999999, 0.9375000000000001, 0.8982, 0.8268, 0.7085999999999999, 0.5498, 0.36, 0.17919999999999997, 0.06, 0.0115, 0.0011, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of Xformer: [0.9907999999999999, 0.9847, 0.9782999999999998, 0.9629999999999999, 0.9279999999999999, 0.8838, 0.7976000000000001, 0.648, 0.4584, 0.2806, 0.16210000000000002, 0.1125, 0.10020000000000001, 0.09809999999999998, 0.09819999999999998, 0.09819999999999998, 0.09819999999999998, 0.09819999999999998, 0.09819999999999998, 0.09819999999999998]
Time taken = 24.833870887756348 seconds
tensor([[0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')
Info positions : [ 7  9 10 11 12 13 14 15]
Target Info positions : [ 7  9 10 11 12 13 14 15]
Frozen positions : [0 1 2 3 4 5 6 8]
Code : polar 
embed dim : 64 
Rate Profile : polar
Batch size : 128
Validation SNR : None
Number of heads : 1
Number of layers: 3
Positional encoding : static
Layers : compelete
Print frequency: 100
Num of steps: 400000
64
TESTING :
Model loaded at step 7000
tensor([[0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')
Test SNRs :  [-10.0, -8.421052631578947, -6.842105263157895, -5.2631578947368425, -3.6842105263157894, -2.1052631578947363, -0.526315789473685, 1.0526315789473681, 2.6315789473684212, 4.210526315789474, 5.789473684210527, 7.368421052631579, 8.94736842105263, 10.526315789473685, 12.105263157894736, 13.684210526315791, 15.263157894736842, 16.842105263157894, 18.42105263157895, 20.0]
BERs of Xformer: [0.48107500374317175, 0.47497499883174893, 0.4596250027418137, 0.44563750326633456, 0.4229750007390976, 0.3759124994277954, 0.3270500004291534, 0.24563749730587003, 0.16452499926090242, 0.08271249979734423, 0.03739999961107969, 0.016700000129640104, 0.012175000086426734, 0.0115124998614192, 0.011474999971687794, 0.011474999971687794, 0.011474999971687794, 0.011474999971687794, 0.011474999971687794, 0.011474999971687794]
BERs of SC decoding: [0.4526625007390976, 0.43682499825954435, 0.4079250007867813, 0.3713625013828278, 0.3139875024557114, 0.2394750013947487, 0.1534250020980835, 0.07576249986886976, 0.02451249994337559, 0.005475000047590583, 0.0006000000052154063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of SCL decoding: [0.4526874959468841, 0.436537504196167, 0.4076499968767166, 0.37116250097751624, 0.3147624969482422, 0.2393624991178513, 0.15331249982118605, 0.07604999914765358, 0.024625000171363348, 0.005425000039394945, 0.0006000000052154063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of ML: [0.4526874959468841, 0.436537504196167, 0.4076499968767166, 0.37116250097751624, 0.3147624969482422, 0.2393624991178513, 0.15331249982118605, 0.07604999914765358, 0.024625000171363348, 0.005425000039394945, 0.0006000000052154063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of ML: [0.9462999999999999, 0.9153, 0.8740000000000001, 0.8032, 0.6986000000000001, 0.5509999999999999, 0.3602, 0.18330000000000002, 0.0607, 0.013600000000000001, 0.0017000000000000003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of bitML: [0.44636250138282774, 0.4328375041484833, 0.401925003528595, 0.36698750555515286, 0.3104374974966049, 0.23659999966621398, 0.15208749920129777, 0.07522500008344649, 0.02453750018030405, 0.005462500068824739, 0.0006000000052154063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of bitML: [0.9610000000000001, 0.9335, 0.8909, 0.8264999999999999, 0.7203999999999999, 0.5662, 0.3693, 0.18749999999999997, 0.0617, 0.013900000000000001, 0.0017000000000000003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of Xformer: [0.9893000000000001, 0.984, 0.9772999999999998, 0.9618, 0.9385, 0.8806999999999999, 0.7941999999999999, 0.6383, 0.4571, 0.2545, 0.1391, 0.0868, 0.0758, 0.07440000000000001, 0.0741, 0.0741, 0.0741, 0.0741, 0.0741, 0.0741]
Time taken = 24.799936771392822 seconds
tensor([[0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')
Info positions : [ 7  9 10 11 12 13 14 15]
Target Info positions : [ 7  9 10 11 12 13 14 15]
Frozen positions : [0 1 2 3 4 5 6 8]
Code : polar 
embed dim : 64 
Rate Profile : polar
Batch size : 128
Validation SNR : None
Number of heads : 1
Number of layers: 3
Positional encoding : static
Layers : compelete
Print frequency: 100
Num of steps: 400000
64
TESTING :
Model loaded at step 8000
tensor([[0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')
Test SNRs :  [-10.0, -8.421052631578947, -6.842105263157895, -5.2631578947368425, -3.6842105263157894, -2.1052631578947363, -0.526315789473685, 1.0526315789473681, 2.6315789473684212, 4.210526315789474, 5.789473684210527, 7.368421052631579, 8.94736842105263, 10.526315789473685, 12.105263157894736, 13.684210526315791, 15.263157894736842, 16.842105263157894, 18.42105263157895, 20.0]
BERs of Xformer: [0.48132500350475316, 0.4698749959468841, 0.45913749635219575, 0.44397500157356257, 0.42071250081062317, 0.3797375023365021, 0.32527500391006464, 0.25442499965429305, 0.17100000232458112, 0.09267500117421151, 0.048737499862909324, 0.03214999977499247, 0.028899999894201753, 0.028812499716877937, 0.028574999794363978, 0.028574999794363978, 0.028574999794363978, 0.028574999794363978, 0.028574999794363978, 0.028574999794363978]
BERs of SC decoding: [0.4578624993562699, 0.4347124993801117, 0.40774999856948846, 0.36850000321865084, 0.3132375001907348, 0.23702500015497205, 0.15391250103712084, 0.07779999971389771, 0.025925000011920926, 0.005087499995715916, 0.0004000000029918738, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of SCL decoding: [0.4569624990224838, 0.4344249963760376, 0.4075499981641769, 0.3680375009775162, 0.3133250057697296, 0.23635000139474868, 0.1529999986290932, 0.07716250158846377, 0.02597499992698431, 0.005087499995715916, 0.0004000000029918738, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of ML: [0.4569624990224838, 0.4344249963760376, 0.4075499981641769, 0.3680375009775162, 0.3133250057697296, 0.23635000139474868, 0.1529999986290932, 0.07716250158846377, 0.02597499992698431, 0.005087499995715916, 0.0004000000029918738, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of ML: [0.9513, 0.9154, 0.8709999999999999, 0.8022, 0.6977, 0.5423, 0.3544, 0.1818, 0.0635, 0.0124, 0.0012000000000000001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of bitML: [0.45271250009536745, 0.4304750055074692, 0.40274999737739564, 0.36304999589920045, 0.3090875029563903, 0.23348749876022337, 0.15131250023841855, 0.07589999996125697, 0.025775000080466272, 0.005025000032037497, 0.0004000000029918738, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of bitML: [0.9655, 0.9338, 0.8934, 0.8258999999999999, 0.7183, 0.5602999999999999, 0.3641, 0.18460000000000001, 0.06430000000000001, 0.012499999999999999, 0.0012000000000000001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of Xformer: [0.9898000000000001, 0.9844999999999998, 0.9766999999999999, 0.9632000000000001, 0.9383, 0.8851, 0.7934, 0.6582, 0.47509999999999997, 0.2894, 0.17390000000000003, 0.1326, 0.1233, 0.122, 0.12169999999999999, 0.12169999999999999, 0.12169999999999999, 0.12169999999999999, 0.12169999999999999, 0.12169999999999999]
Time taken = 24.513411045074463 seconds
tensor([[0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')
Info positions : [ 7  9 10 11 12 13 14 15]
Target Info positions : [ 7  9 10 11 12 13 14 15]
Frozen positions : [0 1 2 3 4 5 6 8]
Code : polar 
embed dim : 64 
Rate Profile : polar
Batch size : 128
Validation SNR : None
Number of heads : 1
Number of layers: 3
Positional encoding : static
Layers : compelete
Print frequency: 100
Num of steps: 400000
64
TESTING :
Model loaded at step 9000
tensor([[0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')
Test SNRs :  [-10.0, -8.421052631578947, -6.842105263157895, -5.2631578947368425, -3.6842105263157894, -2.1052631578947363, -0.526315789473685, 1.0526315789473681, 2.6315789473684212, 4.210526315789474, 5.789473684210527, 7.368421052631579, 8.94736842105263, 10.526315789473685, 12.105263157894736, 13.684210526315791, 15.263157894736842, 16.842105263157894, 18.42105263157895, 20.0]
BERs of Xformer: [0.4805749952793122, 0.4776250034570694, 0.4628374993801117, 0.4494625002145767, 0.42637500166893005, 0.3889250010251999, 0.33083750009536744, 0.2530125036835671, 0.16757500022649766, 0.09241249933838844, 0.04268750026822089, 0.025250000134110447, 0.020487499982118604, 0.020124999992549422, 0.02016249988228083, 0.020124999992549422, 0.020124999992549422, 0.020124999992549422, 0.020124999992549422, 0.020124999992549422]
BERs of SC decoding: [0.4514625012874603, 0.43599999845027915, 0.40854999721050256, 0.37314999997615816, 0.311574998497963, 0.23853749781847, 0.1526875004172325, 0.07715000063180924, 0.02564999982714653, 0.0059625000692904, 0.0007750000047963113, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of SCL decoding: [0.4516375035047531, 0.4358000010251999, 0.4090124905109406, 0.37397499978542326, 0.31130000054836277, 0.23822500109672545, 0.1521249979734421, 0.07686249986290931, 0.025224999897181993, 0.0059625000692904, 0.0007750000047963113, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of ML: [0.4516375035047531, 0.4358000010251999, 0.4090124905109406, 0.37397499978542326, 0.31130000054836277, 0.23822500109672545, 0.1521249979734421, 0.07686249986290931, 0.025224999897181993, 0.0059625000692904, 0.0007750000047963113, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of ML: [0.9422999999999999, 0.9169, 0.8685999999999999, 0.8046000000000002, 0.6888000000000001, 0.5425, 0.3619, 0.18480000000000002, 0.06230000000000001, 0.0138, 0.0019, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of bitML: [0.44675000309944163, 0.4300625026226043, 0.4031624972820282, 0.36786249876022337, 0.3064499974250794, 0.23601249903440477, 0.1501124992966652, 0.07632499933242796, 0.02521250005811453, 0.00598750002682209, 0.0007750000047963113, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of bitML: [0.9577, 0.9374, 0.8876000000000001, 0.8237, 0.7074, 0.56, 0.3707, 0.18960000000000002, 0.0636, 0.013900000000000003, 0.0019, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of Xformer: [0.9885000000000002, 0.9828, 0.9763000000000001, 0.9641, 0.936, 0.8896, 0.7928000000000001, 0.6475000000000001, 0.45409999999999995, 0.25980000000000003, 0.12969999999999998, 0.0763, 0.0606, 0.058399999999999994, 0.0584, 0.0582, 0.0582, 0.0582, 0.0582, 0.0582]
Time taken = 24.400556564331055 seconds
tensor([[0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')
Info positions : [ 7  9 10 11 12 13 14 15]
Target Info positions : [ 7  9 10 11 12 13 14 15]
Frozen positions : [0 1 2 3 4 5 6 8]
Code : polar 
embed dim : 64 
Rate Profile : polar
Batch size : 128
Validation SNR : None
Number of heads : 1
Number of layers: 3
Positional encoding : static
Layers : compelete
Print frequency: 100
Num of steps: 400000
64
TESTING :
Model loaded at step 10000
tensor([[0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')
Test SNRs :  [-10.0, -8.421052631578947, -6.842105263157895, -5.2631578947368425, -3.6842105263157894, -2.1052631578947363, -0.526315789473685, 1.0526315789473681, 2.6315789473684212, 4.210526315789474, 5.789473684210527, 7.368421052631579, 8.94736842105263, 10.526315789473685, 12.105263157894736, 13.684210526315791, 15.263157894736842, 16.842105263157894, 18.42105263157895, 20.0]
BERs of Xformer: [0.4869499981403351, 0.4797374963760376, 0.4659249991178513, 0.4498125016689301, 0.4228750020265579, 0.391737499833107, 0.32818749845027917, 0.25670000165700907, 0.1675125002861023, 0.08428749963641166, 0.033050000295043, 0.011937499884516001, 0.005949999950826168, 0.005249999975785613, 0.0051375000271946195, 0.0051375000271946195, 0.0051375000271946195, 0.0051375000271946195, 0.0051375000271946195, 0.0051375000271946195]
BERs of SC decoding: [0.45703749954700457, 0.44024999737739573, 0.41329999864101413, 0.36957500576972957, 0.31171249747276303, 0.24236250221729277, 0.15048750042915346, 0.07922499999403954, 0.028762500174343585, 0.005312500125728548, 0.0005875000060768798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of SCL decoding: [0.45671250224113463, 0.4391874998807907, 0.41362499892711646, 0.3695624947547913, 0.3106875002384186, 0.2425125002861023, 0.14993750005960463, 0.07876249998807909, 0.02846250012516975, 0.005362500110641122, 0.0005875000060768798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of ML: [0.45671250224113463, 0.4391874998807907, 0.41362499892711646, 0.3695624947547913, 0.3106875002384186, 0.2425125002861023, 0.14993750005960463, 0.07876249998807909, 0.02846250012516975, 0.005362500110641122, 0.0005875000060768798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of ML: [0.9468999999999999, 0.917, 0.8778, 0.8033, 0.6977, 0.5547000000000001, 0.35269999999999996, 0.18740000000000004, 0.06620000000000001, 0.0122, 0.0012000000000000003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BERs of bitML: [0.45185000002384185, 0.43310000300407414, 0.407549998164177, 0.36527500152587894, 0.30653750002384184, 0.23885000050067903, 0.14652499854564668, 0.07747500091791153, 0.028437499701976777, 0.005375000112690031, 0.0005875000060768798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of bitML: [0.9605999999999999, 0.9342999999999999, 0.8944000000000001, 0.8264, 0.7172000000000001, 0.5701999999999999, 0.3604, 0.19180000000000003, 0.0671, 0.0123, 0.0012000000000000003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
BLERs of Xformer: [0.9905999999999999, 0.9838000000000002, 0.9777, 0.962, 0.9359, 0.8887000000000002, 0.7902000000000001, 0.6522999999999999, 0.4467, 0.2518, 0.1193, 0.06, 0.04390000000000001, 0.041299999999999996, 0.041100000000000005, 0.041100000000000005, 0.041100000000000005, 0.041100000000000005, 0.041100000000000005, 0.041100000000000005]
Time taken = 24.290754318237305 seconds
tensor([[0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')
60
100
Mean BER (Noisy): 0.1466
Mean Bitwise BER (Noisy):
  Row 0: 0.0109
  Row 1: 0.1953
  Row 2: 0.2144
  Row 3: 0.146
  Row 4: 0.1964
  Row 5: 0.1573
  Row 6: 0.1588
  Row 7: 0.0937
Info positions : [ 7  9 10 11 12 13 14 15]
Target Info positions : [ 7  9 10 11 12 13 14 15]
Frozen positions : [0 1 2 3 4 5 6 8]
embed dim : 64 
Batch size : 128
Validation SNR : None
Train SNR : 3.0
load training data? False
Number of heads : 1
Number of layers: 3
Positional encoding : static
Print frequency: 1000
Num of steps: 400000
combinational training snr:  False
64
Training Model for 8,16 anew
Number of parameters : 150471
Did not find standard validation data
Need to save for: 500
tensor([[-1., -1., -1., -1., -1., -1., -1., -1.]], device='cuda:0')
tensor([[ 1.,  1.,  1., -1.,  1., -1.,  1., -1.]], device='cuda:0')
Model loaded at step 10000
------- training data -------
Example: 0
Original Message Bits: [-1. -1. -1. -1. -1. -1. -1. -1.]
Info positions : [ 7  9 10 11 12 13 14 15]
Target Info positions : [ 7  9 10 11 12 13 14 15]
Frozen positions : [0 1 2 3 4 5 6 8]
embed dim : 64 
Batch size : 128
Validation SNR : None
Train SNR : 3.0
load training data? False
Number of heads : 1
Number of layers: 3
Positional encoding : static
Print frequency: 1000
Num of steps: 400000
combinational training snr:  False
64
Training Model for 8,16 anew
Number of parameters : 150471
Did not find standard validation data
Need to save for: 500
tensor([[-1., -1., -1., -1., -1., -1., -1., -1.]], device='cuda:0')
tensor([[ 1.,  1., -1., -1.,  1., -1.,  1.,  1.]], device='cuda:0')
Model loaded at step 10000
------- training data -------
Example: 0
Original Message Bits: [-1. -1. -1. -1. -1. -1. -1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]]

Example: 1
Original Message Bits: [-1. -1. -1. -1. -1. -1. -1.  1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]]

Example: 2
Original Message Bits: [-1. -1. -1. -1. -1. -1.  1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]]

Example: 3
Original Message Bits: [-1. -1. -1. -1. -1.  1. -1. -1.]
Decoded Bits: [[-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]]

Example: 4
Original Message Bits: [-1. -1. -1. -1. -1.  1. -1.  1.]
Decoded Bits: [[ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]]

Example: 5
Original Message Bits: [-1. -1. -1. -1. -1.  1.  1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]]

Example: 6
Original Message Bits: [-1. -1. -1. -1. -1.  1.  1.  1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]]

Example: 7
Original Message Bits: [-1. -1. -1. -1.  1. -1. -1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]]

Example: 8
Original Message Bits: [-1. -1. -1. -1.  1. -1.  1. -1.]
Decoded Bits: [[ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]]

Example: 9
Original Message Bits: [-1. -1. -1. -1.  1. -1.  1.  1.]
Decoded Bits: [[ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]]

Example: 10
Original Message Bits: [-1. -1. -1. -1.  1.  1. -1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]]

Example: 11
Original Message Bits: [-1. -1. -1. -1.  1.  1. -1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]]

Example: 12
Original Message Bits: [-1. -1. -1. -1.  1.  1.  1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]]

Example: 13
Original Message Bits: [-1. -1. -1. -1.  1.  1.  1.  1.]
Decoded Bits: [[ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]]

Example: 14
Original Message Bits: [-1. -1. -1.  1. -1. -1. -1.  1.]
Decoded Bits: [[-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]]

Example: 15
Original Message Bits: [-1. -1. -1.  1. -1. -1.  1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]]

Example: 16
Original Message Bits: [-1. -1. -1.  1. -1. -1.  1.  1.]
Decoded Bits: [[ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]]

Example: 17
Original Message Bits: [-1. -1. -1.  1. -1.  1. -1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]]

Example: 18
Original Message Bits: [-1. -1. -1.  1. -1.  1. -1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]]

Example: 19
Original Message Bits: [-1. -1. -1.  1. -1.  1.  1.  1.]
Decoded Bits: [[-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]]

Example: 20
Original Message Bits: [-1. -1. -1.  1.  1. -1. -1. -1.]
Decoded Bits: [[ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]]

Example: 21
Original Message Bits: [-1. -1. -1.  1.  1. -1. -1.  1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]]

Example: 22
Original Message Bits: [-1. -1. -1.  1.  1. -1.  1. -1.]
Decoded Bits: [[-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]]

Example: 23
Original Message Bits: [-1. -1. -1.  1.  1. -1.  1.  1.]
Decoded Bits: [[-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]]

Example: 24
Original Message Bits: [-1. -1. -1.  1.  1.  1. -1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]]

Example: 25
Original Message Bits: [-1. -1. -1.  1.  1.  1. -1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]]

Example: 26
Original Message Bits: [-1. -1. -1.  1.  1.  1.  1. -1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]]

Example: 27
Original Message Bits: [-1. -1. -1.  1.  1.  1.  1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]]

Example: 28
Original Message Bits: [-1. -1.  1. -1. -1. -1. -1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]]

Example: 29
Original Message Bits: [-1. -1.  1. -1. -1. -1. -1.  1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]]

Example: 30
Original Message Bits: [-1. -1.  1. -1. -1. -1.  1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]]

Example: 31
Original Message Bits: [-1. -1.  1. -1. -1. -1.  1.  1.]
Decoded Bits: [[-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]]

Example: 32
Original Message Bits: [-1. -1.  1. -1. -1.  1. -1. -1.]
Decoded Bits: [[ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]]

Example: 33
Original Message Bits: [-1. -1.  1. -1. -1.  1. -1.  1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]]

Example: 34
Original Message Bits: [-1. -1.  1. -1. -1.  1.  1.  1.]
Decoded Bits: [[ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]]

Example: 35
Original Message Bits: [-1. -1.  1. -1.  1. -1. -1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]]

Example: 36
Original Message Bits: [-1. -1.  1. -1.  1. -1.  1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]]

Example: 37
Original Message Bits: [-1. -1.  1. -1.  1.  1. -1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]]

Example: 38
Original Message Bits: [-1. -1.  1. -1.  1.  1. -1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]]

Example: 39
Original Message Bits: [-1. -1.  1. -1.  1.  1.  1. -1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]]

Example: 40
Original Message Bits: [-1. -1.  1.  1. -1. -1. -1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]]

Example: 41
Original Message Bits: [-1. -1.  1.  1. -1. -1. -1.  1.]
Decoded Bits: [[-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]]

Example: 42
Original Message Bits: [-1. -1.  1.  1. -1. -1.  1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]]

Example: 43
Original Message Bits: [-1. -1.  1.  1. -1. -1.  1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]]

Example: 44
Original Message Bits: [-1. -1.  1.  1. -1.  1. -1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]]

Example: 45
Original Message Bits: [-1. -1.  1.  1. -1.  1. -1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]]

Example: 46
Original Message Bits: [-1. -1.  1.  1. -1.  1.  1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]]

Example: 47
Original Message Bits: [-1. -1.  1.  1. -1.  1.  1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]]

Example: 48
Original Message Bits: [-1. -1.  1.  1.  1. -1. -1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]]

Example: 49
Original Message Bits: [-1. -1.  1.  1.  1. -1. -1.  1.]
Decoded Bits: [[ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]]

Example: 50
Original Message Bits: [-1. -1.  1.  1.  1. -1.  1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]]

Example: 51
Original Message Bits: [-1. -1.  1.  1.  1. -1.  1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]]

Example: 52
Original Message Bits: [-1. -1.  1.  1.  1.  1. -1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]]

Example: 53
Original Message Bits: [-1. -1.  1.  1.  1.  1. -1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]]

Example: 54
Original Message Bits: [-1. -1.  1.  1.  1.  1.  1. -1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]]

Example: 55
Original Message Bits: [-1. -1.  1.  1.  1.  1.  1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]]

Example: 56
Original Message Bits: [-1.  1. -1. -1. -1. -1.  1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]]

Example: 57
Original Message Bits: [-1.  1. -1. -1. -1. -1.  1.  1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]]

Example: 58
Original Message Bits: [-1.  1. -1. -1. -1.  1. -1. -1.]
Decoded Bits: [[-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]]

Example: 59
Original Message Bits: [-1.  1. -1. -1. -1.  1. -1.  1.]
Decoded Bits: [[-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]]

Example: 60
Original Message Bits: [-1.  1. -1. -1. -1.  1.  1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]]

Example: 61
Original Message Bits: [-1.  1. -1. -1.  1. -1. -1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]]

Example: 62
Original Message Bits: [-1.  1. -1. -1.  1. -1. -1.  1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]]

Example: 63
Original Message Bits: [-1.  1. -1. -1.  1. -1.  1. -1.]
Decoded Bits: [[ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]]

Example: 64
Original Message Bits: [-1.  1. -1. -1.  1. -1.  1.  1.]
Decoded Bits: [[ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]]

Example: 65
Original Message Bits: [-1.  1. -1. -1.  1.  1. -1. -1.]
Decoded Bits: [[-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]]

Example: 66
Original Message Bits: [-1.  1. -1. -1.  1.  1. -1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]]

Example: 67
Original Message Bits: [-1.  1. -1. -1.  1.  1.  1. -1.]
Decoded Bits: [[-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]]

Example: 68
Original Message Bits: [-1.  1. -1.  1. -1. -1. -1. -1.]
Decoded Bits: [[-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]]

Example: 69
Original Message Bits: [-1.  1. -1.  1. -1. -1. -1.  1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]]

Example: 70
Original Message Bits: [-1.  1. -1.  1. -1.  1. -1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]]

Example: 71
Original Message Bits: [-1.  1. -1.  1. -1.  1. -1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]]

Example: 72
Original Message Bits: [-1.  1. -1.  1. -1.  1.  1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]]

Example: 73
Original Message Bits: [-1.  1. -1.  1. -1.  1.  1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]]

Example: 74
Original Message Bits: [-1.  1. -1.  1.  1. -1. -1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]]

Example: 75
Original Message Bits: [-1.  1. -1.  1.  1. -1. -1.  1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]]

Example: 76
Original Message Bits: [-1.  1. -1.  1.  1. -1.  1. -1.]
Decoded Bits: [[ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]]

Example: 77
Original Message Bits: [-1.  1. -1.  1.  1. -1.  1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]]

Example: 78
Original Message Bits: [-1.  1. -1.  1.  1.  1. -1. -1.]
Decoded Bits: [[ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]]

Example: 79
Original Message Bits: [-1.  1. -1.  1.  1.  1.  1. -1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]]

Example: 80
Original Message Bits: [-1.  1.  1. -1. -1. -1. -1.  1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]]

Example: 81
Original Message Bits: [-1.  1.  1. -1. -1. -1.  1.  1.]
Decoded Bits: [[ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]]

Example: 82
Original Message Bits: [-1.  1.  1. -1. -1.  1. -1.  1.]
Decoded Bits: [[ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]]

Example: 83
Original Message Bits: [-1.  1.  1. -1. -1.  1.  1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]]

Example: 84
Original Message Bits: [-1.  1.  1. -1. -1.  1.  1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]]

Example: 85
Original Message Bits: [-1.  1.  1. -1.  1. -1.  1. -1.]
Decoded Bits: [[ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]]

Example: 86
Original Message Bits: [-1.  1.  1. -1.  1.  1. -1. -1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]]

Example: 87
Original Message Bits: [-1.  1.  1. -1.  1.  1. -1.  1.]
Decoded Bits: [[ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]]

Example: 88
Original Message Bits: [-1.  1.  1. -1.  1.  1.  1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]]

Example: 89
Original Message Bits: [-1.  1.  1.  1. -1. -1.  1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]]

Example: 90
Original Message Bits: [-1.  1.  1.  1. -1. -1.  1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]]

Example: 91
Original Message Bits: [-1.  1.  1.  1. -1.  1. -1. -1.]
Decoded Bits: [[-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]]

Example: 92
Original Message Bits: [-1.  1.  1.  1. -1.  1. -1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]]

Example: 93
Original Message Bits: [-1.  1.  1.  1. -1.  1.  1. -1.]
Decoded Bits: [[-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]]

Example: 94
Original Message Bits: [-1.  1.  1.  1. -1.  1.  1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]]

Example: 95
Original Message Bits: [-1.  1.  1.  1.  1. -1. -1.  1.]
Decoded Bits: [[ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]]

Example: 96
Original Message Bits: [-1.  1.  1.  1.  1. -1.  1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]]

Example: 97
Original Message Bits: [-1.  1.  1.  1.  1. -1.  1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]]

Example: 98
Original Message Bits: [-1.  1.  1.  1.  1.  1. -1. -1.]
Decoded Bits: [[-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]]

Example: 99
Original Message Bits: [-1.  1.  1.  1.  1.  1. -1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]]

Example: 100
Original Message Bits: [-1.  1.  1.  1.  1.  1.  1. -1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]]

Example: 101
Original Message Bits: [-1.  1.  1.  1.  1.  1.  1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]]

Example: 102
Original Message Bits: [ 1. -1. -1. -1. -1. -1. -1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]]

Example: 103
Original Message Bits: [ 1. -1. -1. -1. -1. -1.  1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]]

Example: 104
Original Message Bits: [ 1. -1. -1. -1. -1. -1.  1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]]

Example: 105
Original Message Bits: [ 1. -1. -1. -1. -1.  1. -1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]]

Example: 106
Original Message Bits: [ 1. -1. -1. -1. -1.  1. -1.  1.]
Decoded Bits: [[ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]]

Example: 107
Original Message Bits: [ 1. -1. -1. -1. -1.  1.  1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]]

Example: 108
Original Message Bits: [ 1. -1. -1. -1.  1. -1.  1. -1.]
Decoded Bits: [[ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]]

Example: 109
Original Message Bits: [ 1. -1. -1. -1.  1.  1. -1. -1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]]

Example: 110
Original Message Bits: [ 1. -1. -1. -1.  1.  1. -1.  1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]]

Example: 111
Original Message Bits: [ 1. -1. -1. -1.  1.  1.  1. -1.]
Decoded Bits: [[ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]]

Example: 112
Original Message Bits: [ 1. -1. -1. -1.  1.  1.  1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]]

Example: 113
Original Message Bits: [ 1. -1. -1.  1. -1. -1. -1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]]

Example: 114
Original Message Bits: [ 1. -1. -1.  1. -1. -1. -1.  1.]
Decoded Bits: [[ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]]

Example: 115
Original Message Bits: [ 1. -1. -1.  1. -1. -1.  1.  1.]
Decoded Bits: [[-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]]

Example: 116
Original Message Bits: [ 1. -1. -1.  1. -1.  1. -1. -1.]
Decoded Bits: [[-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]]

Example: 117
Original Message Bits: [ 1. -1. -1.  1. -1.  1. -1.  1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]]

Example: 118
Original Message Bits: [ 1. -1. -1.  1. -1.  1.  1. -1.]
Decoded Bits: [[-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]]

Example: 119
Original Message Bits: [ 1. -1. -1.  1. -1.  1.  1.  1.]
Decoded Bits: [[-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]]

Example: 120
Original Message Bits: [ 1. -1. -1.  1.  1. -1. -1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]]

Example: 121
Original Message Bits: [ 1. -1. -1.  1.  1. -1. -1.  1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]]

Example: 122
Original Message Bits: [ 1. -1. -1.  1.  1. -1.  1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [-1.]]

Example: 123
Original Message Bits: [ 1. -1. -1.  1.  1. -1.  1.  1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]]

Example: 124
Original Message Bits: [ 1. -1. -1.  1.  1.  1. -1.  1.]
Decoded Bits: [[ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [ 1.]]

Example: 125
Original Message Bits: [ 1. -1. -1.  1.  1.  1.  1. -1.]
Decoded Bits: [[ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [ 1.]
 [-1.]]

Example: 126
Original Message Bits: [ 1. -1.  1. -1. -1. -1. -1. -1.]
Decoded Bits: [[-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]]

Example: 127
Original Message Bits: [ 1. -1.  1. -1. -1. -1. -1.  1.]
Decoded Bits: [[-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [ 1.]
 [-1.]
 [-1.]
 [-1.]
 [-1.]
 [ 1.]]

Info positions : [ 7  9 10 11 12 13 14 15]
Target Info positions : [ 7  9 10 11 12 13 14 15]
Frozen positions : [0 1 2 3 4 5 6 8]
embed dim : 64 
Batch size : 128
Validation SNR : None
Train SNR : 3.0
load training data? False
Number of heads : 1
Number of layers: 3
Positional encoding : static
Print frequency: 1000
Num of steps: 400000
combinational training snr:  False
64
Training Model for 8,16 anew
Number of parameters : 150471
Did not find standard validation data
Need to save for: 500
tensor([[-1., -1., -1., -1., -1., -1., -1., -1.]], device='cuda:0')
tensor([[-1.,  1., -1., -1., -1.,  1., -1.,  1.]], device='cuda:0')
Model loaded at step 5000
------- training data -------
Info positions : [ 7  9 10 11 12 13 14 15]
Target Info positions : [ 7  9 10 11 12 13 14 15]
Frozen positions : [0 1 2 3 4 5 6 8]
embed dim : 64 
Batch size : 128
Validation SNR : None
Train SNR : 3.0
load training data? False
Number of heads : 1
Number of layers: 3
Positional encoding : static
Print frequency: 1000
Num of steps: 400000
combinational training snr:  False
64
Training Model for 8,16 anew
Number of parameters : 150471
Did not find standard validation data
Need to save for: 500
tensor([[-1., -1., -1., -1., -1., -1., -1.,  1.]], device='cuda:0')
tensor([[-1.,  1.,  1.,  1., -1.,  1., -1., -1.]], device='cuda:0')
Model loaded at step 5000
------- training data -------
Example: 100
Original Message Bits:  [-1.  1.  1.  1.  1.  1.  1. -1.]
Decoded Bits:           [-1. -1.  1.  1.  1. -1. -1.  1.]

Example: 145
Original Message Bits:  [ 1. -1.  1.  1. -1.  1. -1. -1.]
Decoded Bits:           [ 1. -1.  1.  1. -1.  1.  1. -1.]

Info positions : [ 7  9 10 11 12 13 14 15]
Target Info positions : [ 7  9 10 11 12 13 14 15]
Frozen positions : [0 1 2 3 4 5 6 8]
embed dim : 64 
Batch size : 128
Validation SNR : None
Train SNR : 3.0
load training data? False
Number of heads : 1
Number of layers: 3
Positional encoding : static
Print frequency: 1000
Num of steps: 400000
combinational training snr:  False
64
Training Model for 8,16 anew
Number of parameters : 150471
Did not find standard validation data
Need to save for: 500
tensor([[-1., -1., -1., -1., -1., -1., -1.,  1.]], device='cuda:0')
tensor([[ 1.,  1., -1.,  1., -1., -1.,  1., -1.]], device='cuda:0')
Model loaded at step 5000
------- training data , messages that are decoded wrongly -------
Example: 100
Original Message Bits:  [-1.  1.  1.  1.  1.  1.  1. -1.]
Decoded Bits:           [-1. -1.  1.  1.  1. -1. -1.  1.]

Example: 145
Original Message Bits:  [ 1. -1.  1.  1. -1.  1. -1. -1.]
Decoded Bits:           [ 1. -1.  1.  1. -1.  1.  1. -1.]

Example: 188
Original Message Bits:  [ 1.  1.  1. -1.  1. -1.  1. -1.]
Decoded Bits:           [ 1.  1. -1. -1.  1. -1.  1. -1.]

------- test data , messages that are decoded wrongly ------- 
Example: 35
Original Message Bits:  [ 1. -1.  1.  1.  1.  1.  1. -1.]
Decoded Bits:           [ 1. -1. -1.  1.  1.  1. -1.  1.]

